<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Unskilled Coder</title>
    <description>Less is more.
</description>
    <link>http://unskilledcoder.github.io/</link>
    <atom:link href="http://unskilledcoder.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 11 Dec 2016 17:37:08 +0800</pubDate>
    <lastBuildDate>Sun, 11 Dec 2016 17:37:08 +0800</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Hadoop Cluster 2.7.3 Installation on CentOS 7 in basic version</title>
        <description>&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;h3 id=&quot;introduction1&quot;&gt;&lt;a href=&quot;#1&quot;&gt;1. Introduction&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;architecture2&quot;&gt;&lt;a href=&quot;#2&quot;&gt;2. Architecture&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;centos-setup3&quot;&gt;&lt;a href=&quot;#3&quot;&gt;3. CentOS setup&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;hadoop-setup4&quot;&gt;&lt;a href=&quot;#4&quot;&gt;4. Hadoop Setup&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;launch-and-shutdown-hadoop-cluster-service5&quot;&gt;&lt;a href=&quot;#5&quot;&gt;5. Launch and Shutdown Hadoop Cluster Service&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;verify-the-hadoop-cluster-is-up-and-healthy6&quot;&gt;&lt;a href=&quot;#6&quot;&gt;6. Verify the hadoop cluster is up and healthy&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;end7&quot;&gt;&lt;a href=&quot;#7&quot;&gt;7. End&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-name11-introductiona&quot;&gt;&lt;a name=&quot;1&quot;&gt;1. Introduction&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;This posts will give all related detail in how to setup a Hadoop cluster on CentOS linux system. Before you read this article, I will assume that you already have all basic conceptions about Hadoop and Linux operating system.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-name22-architecturea&quot;&gt;&lt;a name=&quot;2&quot;&gt;2. Architecture&lt;/a&gt;&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;IP Address&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Hostname&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Role&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;192.168.171.132&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;master&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;NameNode, ResourceManager&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;192.168.171.133&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;slave1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;SecondaryNameNode, DataNode, NodeManager&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;192.168.171.134&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;slave2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;DataNode, NodeManager&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-name33-centos-setupa&quot;&gt;&lt;a name=&quot;3&quot;&gt;3. CentOS setup&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;install-necessary-packages-for-os&quot;&gt;3.1. install necessary packages for OS&lt;/h3&gt;

&lt;p&gt;We pick up CentOS minimal ISO as our installation prototype, once the system installed, we need 2 more basic packages: &lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo yum install -y net-tools
sudo yum install -y openssh-server
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;The first line is to install ifconfig, while the second one is to be able to be ssh login by remote peer.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;setup-hostname-for-all-nodes&quot;&gt;3.2. setup hostname for all nodes&lt;/h3&gt;

&lt;p&gt;This step is optional, but important for better self-identify while you use same username to walk through different nodes.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo hostnamectl &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;-hostname master
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;ex: at &lt;b&gt;master&lt;/b&gt; node&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;re-login to check the effect&lt;/p&gt;

&lt;h3 id=&quot;setup-jdk-for-all-nodes&quot;&gt;3.3. setup jdk for all nodes&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;install jdk from oracle official website&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo wget --header &lt;span class=&quot;s2&quot;&gt;&quot;Cookie: oraclelicense=accept-securebackup-cookie&quot;&lt;/span&gt; http://download.oracle.com/otn-pub/java/jdk/8u112-b14/jdk-8u112-linux-x64.rpm
sudo yum localinstall -y jdk-8u112-linux-x64.rpm
sudo rm jdk-8u112-linux-x64.rpm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;add java.sh under /etc/profile.d/&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;java.sh content:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/java/jdk1.8.0_112
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JRE_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/java/jdk1.8.0_112/jre
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/lib:.
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;re-login, and you’ll find all environment variables, and java is well installed.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Approach to verification:&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java -version
ls &lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;
ls &lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;if the java version goes wrong, you can&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo alternatives --config java
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;then choose a correct version.&lt;/p&gt;

&lt;h3 id=&quot;setup-user-and-user-group-on-all-nodes&quot;&gt;3.4. setup user and user group on all nodes&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo groupadd hadoop
sudo useradd -d /home/hadoop -g hadoop hadoop
passwd hadoop
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;modify-hosts-file-for-network-inter-recognition-on-all-nodes&quot;&gt;3.5. modify hosts file for network inter-recognition on all nodes&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'192.168.171.132 master'&lt;/span&gt; &amp;gt;&amp;gt; /etc/hosts
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'192.168.171.133 slave1'&lt;/span&gt; &amp;gt;&amp;gt; /etc/hosts
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'192.168.171.134 slave2'&lt;/span&gt; &amp;gt;&amp;gt; /etc/hosts
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;check the recognition works:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ping master
ping slave1
ping slave2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;setup-ssh-no-password-login-on-all-nodes&quot;&gt;3.6. setup ssh no password login on all nodes&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su - hadoop
ssh-keygen -t rsa
ssh-copy-id master
ssh-copy-id slave1
ssh-copy-id slave2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;now you can ssh login to all 3 nodes without passwd, please have a try to check it out.
&lt;br /&gt; &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-name44-hadoop-setupa&quot;&gt;&lt;a name=&quot;4&quot;&gt;4. Hadoop Setup&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;P.S. the whole &lt;strong&gt;&lt;a href=&quot;#4&quot;&gt;Step 4&lt;/a&gt;&lt;/strong&gt; operations happens on a single node, let’s say, &lt;em&gt;master&lt;/em&gt;. In addition, we’ll login as user &lt;em&gt;hadoop&lt;/em&gt; to finish all operations.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su - hadoop
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;download-and-untar-on-the-file-system&quot;&gt;4.1. Download and untar on the file system.&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget http://mirrors.sonic.net/apache/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz
untar -zxvf hadoop-2.7.3.tar.gz
rm hadoop-2.7.3.tar.gz
chmod 775 hadoop-2.7.3
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;add-environment-variables-for-hadoop&quot;&gt;4.2. Add environment variables for hadoop&lt;/h3&gt;

&lt;p&gt;append following content onto ~/.bashrc&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/hadoop/hadoop-2.7.3
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_INSTALL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_MAPRED_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_COMMON_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HDFS_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;YARN_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_COMMON_LIB_NATIVE_DIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/lib/native
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;:&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/sbin:&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;then make these variables effect:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;modify-configuration-files-for-hadoop&quot;&gt;4.3. Modify configuration files for hadoop&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Add slave node hostnames into &lt;code class=&quot;highlighter-rouge&quot;&gt;$HADOOP_HOME/etc/hadoop/slaves&lt;/code&gt; file&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;slave1 &amp;gt; &lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/etc/hadoop/slaves
&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;slave2 &amp;gt;&amp;gt; &lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/etc/hadoop/slaves
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Add secondary node hostname into &lt;code class=&quot;highlighter-rouge&quot;&gt;$HADOOP_HOME/etc/hadoop/masters&lt;/code&gt; file&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;slave1 &amp;gt; &lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/etc/hadoop/masters
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Modify &lt;code class=&quot;highlighter-rouge&quot;&gt;$HADOOP_HOME/etc/hadoop/core-site.xml&lt;/code&gt; as following&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://master:9000/&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;namenode settings&lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/home/hadoop/hadoop-2.7.3/tmp/hadoop-${user.name}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt; temp folder &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;  
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.proxyuser.hadoop.hosts&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;*&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.proxyuser.hadoop.groups&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;*&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Modify &lt;code class=&quot;highlighter-rouge&quot;&gt;$HADOOP_HOME/etc/hadoop/hdfs-site.xml&lt;/code&gt; as following&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.http-address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;master:50070&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt; fetch NameNode images and edits &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.secondary.http-address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;slave1:50090&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt; fetch SecondNameNode fsimage &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;2&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt; replica count &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:///home/hadoop/hadoop-2.7.3/hdfs/name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt; namenode &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:///home/hadoop/hadoop-2.7.3/hdfs/data&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt; DataNode &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.checkpoint.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:///home/hadoop/hadoop-2.7.3/hdfs/namesecondary&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;  check point &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.webhdfs.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.stream-buffer-size&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;131072&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt; buffer &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.checkpoint.period&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3600&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;  
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt; duration &lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Modify &lt;code class=&quot;highlighter-rouge&quot;&gt;$HADOOP_HOME/etc/hadoop/mapred-site.xml&lt;/code&gt; as following&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;  
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.framework.name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;yarn&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.jobtracker.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://trucy:9001&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.jobhistory.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;master:10020&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;MapReduce JobHistory Server host:port, default port is 10020.&lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.jobhistory.webapp.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;master:19888&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;MapReduce JobHistory Server Web UI host:port, default port is 19888.&lt;span class=&quot;nt&quot;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Modify &lt;code class=&quot;highlighter-rouge&quot;&gt;$HADOOP_HOME/etc/hadoop/yarn-site.xml&lt;/code&gt; as following&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;master&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mapreduce_shuffle&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;master:8032&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.scheduler.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;master:8030&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.resource-tracker.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;master:8031&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.admin.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;master:8033&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.webapp.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;master:8088&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;create-necessary-folders&quot;&gt;4.4. Create necessary folders&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir -p &lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/tmp
mkdir -p &lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/hdfs/name
mkdir -p &lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/hdfs/data
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;copy-hadoop-folders-and-environment-settings-to-slaves&quot;&gt;4.5. Copy hadoop folders and environment settings to slaves&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;scp ~/.bashrc slave1:~/
scp ~/.bashrc slave2:~/

scp -r ~/hadoop-2.7.3 slave1:~/
scp -r ~/hadoop-2.7.3 slave2:~/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-name55-launch-hadoop-cluster-servicea&quot;&gt;&lt;a name=&quot;5&quot;&gt;5. Launch hadoop cluster service&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Format namenode for the first time launch&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Launch dfs distributed file system&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Launch yarn distributed computing system&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Shutdown Hadoop Cluster&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;stop-yarn.sh
stop-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-name66-verify-the-hadoop-cluster-is-up-and-healthya&quot;&gt;&lt;a name=&quot;6&quot;&gt;6. Verify the hadoop cluster is up and healthy&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&quot;verify-by-jps-processus&quot;&gt;6.1. Verify by jps processus&lt;/h3&gt;

&lt;p&gt;Check &lt;em&gt;jps&lt;/em&gt; on each node, and view results. &lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;jps normal results on &lt;em&gt;master&lt;/em&gt; node:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# jps&lt;/span&gt;
32967 NameNode
33225 Jps
32687 ResourceManager 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;On &lt;em&gt;slave1&lt;/em&gt; node:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# jps&lt;/span&gt;
28227 SecondaryNameNode
28496 Jps
28179 DataNode
28374 NodeManager 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;On &lt;em&gt;slave2&lt;/em&gt; node:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# jps&lt;/span&gt;
27680 DataNode
27904 Jps
27784 NodeManager
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;verify-on-web-interface&quot;&gt;6.2. Verify on Web interface&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;192.168.171.132:50070&lt;/code&gt; to view hdfs storage status. &lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;192.168.171.132:8088&lt;/code&gt; to view yarn computing system resources and application status.&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;a-name77-enda&quot;&gt;&lt;a name=&quot;7&quot;&gt;7. End&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;This is all about basic version of hadoop 3 nodes cluster, for high availability version &amp;amp; hadoop relative eco-systems, I’ll give it on other posts, thanks for contacting me if there is anything mistype or you have any suggestions or anything you don’t understand. Hope you all enjoy the hadoop journey! :)&lt;/p&gt;
</description>
        <pubDate>Sat, 10 Dec 2016 17:00:00 +0800</pubDate>
        <link>http://unskilledcoder.github.io/hadoop/2016/12/10/hadoop-cluster-installation-basic-version.html</link>
        <guid isPermaLink="true">http://unskilledcoder.github.io/hadoop/2016/12/10/hadoop-cluster-installation-basic-version.html</guid>
        
        
        <category>Hadoop</category>
        
      </item>
    
      <item>
        <title>Difference of Java maps (HashMap, HashTable, ConcurrentHashMap)</title>
        <description>&lt;p&gt;Based on different senarios, we are often struggling choosing among different map implementations, like HashMap, HashTable &amp;amp; ConcurrentHashMap. Unlike other articles, I will not show up detail code here, but explain the principle and conceptions. And I highly recommend here you should at least look into the source code yourself for concret notion and deeper impression.&lt;/p&gt;

&lt;h4 id=&quot;hashtable&quot;&gt;HashTable&lt;/h4&gt;

&lt;p&gt;Let me introduce &lt;strong&gt;HashTable&lt;/strong&gt; first, which is the earliest hashmap implementation in Java library above all 3. To make this table fit all senarios, the syncronized keyword is added onto most of its methods to provide thread-safe feature. And it does not accept the null key and value.&lt;/p&gt;

&lt;p&gt;So in javadoc there is a comment for this hashmap:&lt;/p&gt;

&lt;p&gt;If a thread-safe implementation is not needed, it is recommended to use HashMap in place of Hashtable. If a thread-safe highly-concurrent implementation is desired, then it is recommended to use java.util.concurrent.ConcurrentHashMap in place of Hashtable.&lt;/p&gt;

&lt;p&gt;In another word, we should not use this class any longer.&lt;/p&gt;

&lt;h4 id=&quot;hashmap&quot;&gt;HashMap&lt;/h4&gt;
&lt;p&gt;The HashMap class is nothing but the new unsynchronized version of Hashtable (while code between them is not relevant), and it permits nulls.
&lt;br /&gt;
In addition, HashMap has been added a new feature, which is, the linkedlist below each hash barrel will be transformed into red-black tree once the size of the list gets too large.&lt;/p&gt;

&lt;h4 id=&quot;concurrenthashmap&quot;&gt;ConcurrentHashMap&lt;/h4&gt;
&lt;p&gt;So it’s straight forward that, this class is the thread-safe version of HashTable, but in a more reasonable way of implementation. It does not permit nulls neither just like HashTable.&lt;/p&gt;

&lt;p&gt;Its thread-safe mechanism is simply as below:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Volatile level read&lt;/li&gt;
  &lt;li&gt;Lock level write&lt;/li&gt;
  &lt;li&gt;16 locks for 16 ranges of hash barrel for additional performance tuning&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;** &lt;strong&gt;volatile&lt;/strong&gt; keyword promises variable visibility, in assemble code level volatile makes sure that once a thread modifies a volatile variable, forces the change to be written back to the main memory (other threads may all find out the modification happened).&lt;/p&gt;
</description>
        <pubDate>Wed, 26 Oct 2016 17:00:00 +0800</pubDate>
        <link>http://unskilledcoder.github.io/java/core-java/2016/10/26/difference-java-maps.html</link>
        <guid isPermaLink="true">http://unskilledcoder.github.io/java/core-java/2016/10/26/difference-java-maps.html</guid>
        
        
        <category>java</category>
        
        <category>core-java</category>
        
      </item>
    
      <item>
        <title>Everything about JVM</title>
        <description>&lt;p&gt;This post generally is to explain what JVM is &amp;amp; how it works. I’m here to record my understandings of this mistery black box and share them with you.&lt;/p&gt;

&lt;h3 id=&quot;introduction&quot;&gt;1. Introduction&lt;/h3&gt;
&lt;p&gt;As we all know JVM is the abbreviation of Java Virtual Machine, which is the cornerstone of the Java Platform. It mainly owns the following responsibility:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Manage resources between living OS and its inside running code, like all virtual machine do.&lt;/li&gt;
  &lt;li&gt;Optimize the space &amp;amp; time efficiency of the running code.&lt;/li&gt;
  &lt;li&gt;Manage and automate garbage collection of the objects in memory.&lt;/li&gt;
  &lt;li&gt;Manage code loading &amp;amp; initialization.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;focused-points&quot;&gt;2. Focused points&lt;/h3&gt;

&lt;h4 id=&quot;jvm-memory-model--garbage-collection&quot;&gt;2.1. JVM memory model &amp;amp; garbage collection&lt;/h4&gt;

&lt;h4 id=&quot;jvm-memory-model&quot;&gt;2.1.1. JVM memory model&lt;/h4&gt;

&lt;p&gt;Let’s directly get into our topic, the JVM memory model.
The JVM memory can be simply splitted into 3 parts&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Heap Memory&lt;/li&gt;
  &lt;li&gt;Non-heap Memory&lt;/li&gt;
  &lt;li&gt;Other&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Heap memory stores all java objects. Non-heap memory, on another hand, keeps all loaded classes and meta-data. For last “other” memory, stores JVM itself, codes and runtimes.&lt;/p&gt;

&lt;h4 id=&quot;heap-memory--garbage-collection&quot;&gt;2.1.2. Heap memory &amp;amp; Garbage collection&lt;/h4&gt;

&lt;p&gt;The garbage collection is always a popular issue in the c++ based languages, which may cause stop-the-world pause, so that have a big impact on the system response speed.&lt;/p&gt;

&lt;p&gt;Heap memory can be divided into 3 parts, which are: Young generation, Old generation &amp;amp; Permanent generation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Young Generation&lt;/strong&gt; is responsible for containing newly created objects. Once gc is called, JVM will move all survived objects in &lt;strong&gt;Eden&lt;/strong&gt; section to blank-half &lt;strong&gt;Survivor&lt;/strong&gt; section (either &lt;strong&gt;from&lt;/strong&gt; or &lt;strong&gt;to&lt;/strong&gt;). And another half &lt;strong&gt;Survivor&lt;/strong&gt; section moves contained survivor objects to this blank-half section as well. If this &lt;strong&gt;Survivor&lt;/strong&gt; section is full, the rest objects will be moved to the &lt;strong&gt;Old Generation&lt;/strong&gt;. Except this blank-half section, others will be cleaned up. This gc algorithm also called Copying algorithm, which is designed for better performance, but may waste half of memory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Old Generation&lt;/strong&gt; is responsible for keeping long last objects. Once gc happens, the Mark-Sweep-Compact gc algorithm will be applied onto this section, which may have worse performance, but take advantage of memory usage.&lt;/p&gt;

&lt;p&gt;So based on the above description, we should not create and release big objects with high frequency, it’s better to keep objects small, or even create less objects.&lt;/p&gt;

&lt;h4 id=&quot;non-heap-memory&quot;&gt;2.1.3. Non-Heap Memory&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Permanent Generation&lt;/strong&gt; is used for store class related meta-data, which will not participate in gc events.&lt;/p&gt;

&lt;p&gt;In addition, the &lt;strong&gt;Permanent Generation&lt;/strong&gt; is replaced by &lt;strong&gt;Meta-data space&lt;/strong&gt; after Java 8, however they are very similar, except &lt;strong&gt;Meta-data space&lt;/strong&gt; can be dynamically re-size in runtime.
&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;more-points-to-add&quot;&gt;More points to add…&lt;/h4&gt;
&lt;p&gt;Recommended book for JVM : Java Performance (2012) - Charlie Hunt&lt;/p&gt;
</description>
        <pubDate>Sat, 22 Oct 2016 16:43:59 +0800</pubDate>
        <link>http://unskilledcoder.github.io/java/jvm/2016/10/22/everything-about-jvm.html</link>
        <guid isPermaLink="true">http://unskilledcoder.github.io/java/jvm/2016/10/22/everything-about-jvm.html</guid>
        
        
        <category>java</category>
        
        <category>jvm</category>
        
      </item>
    
  </channel>
</rss>
